{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23ef89e1",
    "tags": []
   },
   "source": [
    "# Parámetros globales del *Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c8cc3fb4"
   },
   "outputs": [],
   "source": [
    "# Para definir los path\n",
    "import os\n",
    "\n",
    "# Define si estamos ejecutando el Notebook en nuestro \n",
    "# ordenador (\"local\") o en Google Colab (\"remote\")\n",
    "RUNNING_ENV = \"local\"\n",
    "\n",
    "# Path que vamos a usar como base para el resto de paths\n",
    "BASE_PATH = \"./\" if RUNNING_ENV == \"local\" else \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "\n",
    "# Directorio en el que guardamos los scripts de python que usamos \n",
    "# como libreria propia\n",
    "LIB_PATH = os.path.join(BASE_PATH, \"lib\")\n",
    "\n",
    "# Directorio en el que guardamos los datos de entrenamiento y test\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
    "\n",
    "# Numero de procesos que queremos usar\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Batch size que queremos usar para los dataloaders que usamos\n",
    "DATALOADER_BACH_SIZE = 32\n",
    "\n",
    "# Tamaño del conjunto de triples aleatorios\n",
    "RANDOM_TRIPLETS_DATA_SIZE = 100\n",
    "\n",
    "# Numero de epocas por las que queremos entrenar\n",
    "TRAINING_EPOCHS = 50\n",
    "\n",
    "# Margen para la funcion de perdida\n",
    "MARGIN = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c155001b"
   },
   "source": [
    "# Autorización si estamos usando Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6784bd8",
    "outputId": "d3e8a373-259c-47a3-e421-0328c24549f9"
   },
   "outputs": [],
   "source": [
    "if RUNNING_ENV == \"remote\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67d9d57d"
   },
   "source": [
    "# Importando los módulos que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d2c35e87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Para poder usar ResNet18 preentrenado\n",
    "import torchvision.models as models \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargamos en el Notebook todos los ficheros .py que definen nuestra propia libreria\n",
    "# Usamos esta libreria para escribir el codigo base necesario para llevar a cabo ciertas\n",
    "# tareas del notebook (como el bucle de entrenamiento) que no tienen interes mostrar\n",
    "# en este notebook\n",
    "!cp -r \"$LIB_PATH\"/* .\n",
    "\n",
    "# Ahora que hemos cargado estos ficheros en el Notebook, importamos lo necesario\n",
    "# de nuestra propia libreria\n",
    "import core\n",
    "import time\n",
    "import copy\n",
    "import board\n",
    "import filesystem\n",
    "from train_loggers import ClassificationLogger, SilentLogger, TripletLogger, TrainLogger\n",
    "from models.resnet import *\n",
    "from visualizations import *\n",
    "from custom_loss import triplet_loss_batch_hard\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97c7e921"
   },
   "source": [
    "# Funciones comunes que vamos a usar en el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "08762464"
   },
   "outputs": [],
   "source": [
    "# TODO -- de momento no tenemos nada asi que esto ahora mismo lo podriamos borrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eea5f6b"
   },
   "source": [
    "# Carga del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "452699e8"
   },
   "outputs": [],
   "source": [
    "# Transformaciones que queremos aplicar al cargar los datos\n",
    "# Ahora solo pasamos las imagenes a tensores, pero podriamos hacer aqui normalizaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # TODO -- aqui podemos añadir la normaliazcion de datos\n",
    "])\n",
    "\n",
    "# Cargamos el dataset usando torchvision, que ya tiene el conjunto\n",
    "# preparado para descargar\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root = DATA_PATH,\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root = DATA_PATH,\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform,\n",
    ")\n",
    "\n",
    "# Data loaders para acceder a los datos\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = DATALOADER_BACH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size = DATALOADER_BACH_SIZE,\n",
    "  shuffle = True,\n",
    "  num_workers = NUM_WORKERS,\n",
    "  pin_memory = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c057c3d"
   },
   "source": [
    "# Definiendo las clases con las que vamos a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b0de0753"
   },
   "outputs": [],
   "source": [
    "# Clases con las que vamos a trabajar\n",
    "# Esta lista especifica la relacion numero -> nombre de la forma\n",
    "# classes[numero] = nombre\n",
    "classes = (\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d74819e",
    "tags": []
   },
   "source": [
    "# Análisis Exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73ebca17"
   },
   "source": [
    "Mostramos algunas imágenes con sus clases para asegurar que hemos cargado correctamente las imágenes del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6913658d",
    "outputId": "50342115-f90e-45ff-d2ea-de97540af996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase obtenida es: Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase obtenida es: T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase obtenida es: Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase obtenida es: Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase obtenida es: Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs_to_show = 5\n",
    "\n",
    "for _ in range(imgs_to_show):\n",
    "\n",
    "    # Cargamos un batch de imagenes\n",
    "    images, images_classes = next(iter(train_loader))\n",
    "\n",
    "    # Nos quedamos con la primera imagen del batch\n",
    "    img, img_class = images[0], images_classes[0]\n",
    "\n",
    "    # Mostramos alguna informacion de la imagen\n",
    "    print(f\"La clase obtenida es: {classes[img_class]}\")\n",
    "\n",
    "    # Re-escalamos y mostramos la imagen\n",
    "    img = img.reshape((28, 28))\n",
    "    show_img(img, color_format_range = (-1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64b64e5c"
   },
   "source": [
    "Mostramos ahora unas cuantas imágenes de forma simultánea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "983f7e35"
   },
   "source": [
    "Mostramos ahora los tamaños del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "762ead5e",
    "outputId": "6bbc6a80-47f8-42ed-837e-e3a38befd9f4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 60000 imágenes de entrenamiento\n",
      "Tenemos 10000 imágenes de test\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tenemos {len(train_dataset)} imágenes de entrenamiento\")\n",
    "print(f\"Tenemos {len(test_dataset)} imágenes de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c4ab9cd"
   },
   "source": [
    "# Definiendo el modelo base\n",
    "\n",
    "- A continuación, definimos el modelo que vamos a usasr como base para nuestra red siamesa\n",
    "- Usaremos el modelo pre-entrenado ResNet18, pre-entrenado en ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8d3a00ed"
   },
   "outputs": [],
   "source": [
    "class ResNet18(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # Tomamos el modelo pre-entrenado ResNet18\n",
    "        self.pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # Usamos directamente la red pre-entrenada para hacer el forward\n",
    "        return self.pretrained.forward(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40bdcf53"
   },
   "source": [
    "# Generación de triples\n",
    "\n",
    "- Para entrenar la red siamesa, necesitamos dar triples con los que computar el *triplet loss*\n",
    "- Por ello, es necesaria una fase previa de *triplets mining*\n",
    "- En todos los casos, crearemos *Datasets* de *Pytorch* para representar la creación de los triples\n",
    "- Hacemos esto basándonos el la [documentación oficial de Pytorch](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "142db1bf"
   },
   "source": [
    "## Generación de triples aleatorios\n",
    "\n",
    "- Es la forma más sencilla y directa para generar triples\n",
    "- Usaremos esta generación como baseline para más tarde realizar comparaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "ef0dbb9f",
    "outputId": "f7735afe-8254-4494-d138-059d824b9dfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-056deb44c6f0>:64: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(triplet)\n",
      "<ipython-input-10-056deb44c6f0>:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(triplet)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ/ElEQVR4nO3da6zVVXrH8d8DXrl7uMOggOANkjINwQYmjY0ZY32jxkzVF8ZaEiZmbMakiTXT6Jg0TUzbaV9OghkztJk6mUTNGB0vxEykfTPxYKgCxhHJ6QxyFBBBEAQOPH1x/kyOev7Pc9z/fXPW95OQc85+ztp7nf/eP/Zl/dda5u4C8MdvUq87AKA7CDtQCMIOFIKwA4Ug7EAhLujmjZkZH/0DHebuNt7ljZ7ZzexmM3vHzPaY2cNNrgtAZ1mr4+xmNlnSbyV9W9I+Sa9LutvddwdteGYHOqwTz+zrJO1x973uflrSzyXd2uD6AHRQk7AvlvT7MT/vqy77HDPbZGaDZjbY4LYANNTkA7rxXip86WW6u2+WtFniZTzQS02e2fdJWjLm529I2t+sOwA6pUnYX5e00syWmdlFku6S9Fx7ugWg3Vp+Ge/uI2b2gKSXJU2W9KS772pbzwC0VctDby3dGO/ZgY7ryEk1AL4+CDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQiJb3Z5ckMxuSdEzSWUkj7r62HZ0C0H6Nwl75C3c/1IbrAdBBvIwHCtE07C7pFTPbbmabxvsFM9tkZoNmNtjwtgA0YO7eemOzRe6+38zmSdoq6W/dfVvw+63fGIAJcXcb7/JGz+zuvr/6ekDSs5LWNbk+AJ3TctjNbKqZTT//vaSbJO1sV8cAtFeTT+PnS3rWzM5fz3+5+0tNOlNdV60LLqjv7sjISNi2ydsV9Eb2eGhyn1500UVh/fTp02E969ukSfHz6OTJk8N65MyZM7W16Ji0HHZ33yvpT1ptD6C7GHoDCkHYgUIQdqAQhB0oBGEHCtHoDLqvfGNf4zPoZsyYUVtbtGhR2HbZsmVhfWBgIKyvXr06rE+ZMqW2Nn369LDt7Nmzw/qKFSvCejZEFQ0xffbZZ2HbrG+7d+8O6zfeeGNt7fbbbw/bvvzyy2G9n3XkDDoAXx+EHSgEYQcKQdiBQhB2oBCEHSgEYQcK0Y4FJ7vmrrvuqq3NnTs3bLtq1aqwno2VR/UDBw6EbadOnRrWL7744rB+4YUXhvXoHIDsurNx8pMnT4b1aNqxJF1yySW1tWnTpoVtM9l9GvX96NGjjW67qTVr1tTWFi5cGLZ98cUXW7pNntmBQhB2oBCEHSgEYQcKQdiBQhB2oBCEHShEX81nf+KJJ8L20dhkNh6cicaDpXise+bMmWHbbFnhbBw9a//SS/UreG/bVrtBjyRp/fr1Yf3OO+8M68PDw2E9WnI5Oj9Ako4fPx7Wm9zn8+fPD+t79uxp+bql/PyGWbNm1daipaIlacOGDbW1I0eOaGRkhPnsQMkIO1AIwg4UgrADhSDsQCEIO1AIwg4Uoqvz2SdNmhTO7V68eHHYfmhoqLaWzY2OxjWlfAvfaP3zwcHBsO21114b1rP107M549G5Etkxvfrqq8P6/v37w3o2Fh6NN2dj9Nlc+2ycPjpuJ06cCNsuWLAgrGdj4Zljx47V1rLHaqtbNqfP7Gb2pJkdMLOdYy4bMLOtZvZu9fWy7HoA9NZEXsb/VNLNX7jsYUmvuvtKSa9WPwPoY2nY3X2bpMNfuPhWSVuq77dIuq293QLQbq2+Z5/v7sOS5O7DZjav7hfNbJOkTdX3Ld4cgKY6/gGdu2+WtFmSJk+e/LXd2BH4umt16O1DM1soSdXXeHlVAD3Xatifk3Rv9f29kn7Znu4A6JT0ZbyZPSXpBklzzGyfpB9KelzSL8xso6TfSfrORG5s3rx5uu+++2rr0Vi2FI+7ZmOy2ZzxaNxTitd+v+KKK8K2Z8+eDevZ353NZ7/jjjtqa9lxycb4s3q2/3v0t42MjIRts3MfsjUITp06VVvL/q7smEfXPRHR4y1b03758uW1tXfeeae2lobd3e+uKdXvdA+g73C6LFAIwg4UgrADhSDsQCEIO1CIrk5x/eSTT/TKK6/U1u+5556w/fvvv19by4ZKslN1s+GvJm2zIaJs2eFsiusHH3xQW/v444/Dttl20pnsb4/q2X1y7ty5lvp0XnTcs2Oa9S1rnx33aBrrihUrwrbRls579+6trfHMDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIbo6zn7ixAlt3769tr5169awfTSV9KOPPgrbZuPw2TTUaInebNvrbLw4u+0mfcvGi7Mx/uxvy5ZkjqYWZ/dJJtuyOep7Nk6e1bPpuZdeemlYb7JEW3T+QHRMeWYHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQXR1nz1x11VVhfeXKlbW1559/PmybjRc32RY5GzPNxoOzZY2zZbCjejbfPOtb03UCItn5A9n5Cdlc/ClTptTWsmOePV6a3ufRcc22yY7OjYj6xTM7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOF6Ktx9sHBwbAejRln84czTcaLszHZOXPmhPVp06aF9Wy8OVqjPOtbti3ywMBAWM/mdUd9//TTT8O22Rh/1j46Ltla/tnjKTtHINvKOhqHzx6Lc+fOra2F6weE1zp6w0+a2QEz2znmssfM7H0z21H9uyW7HgC9NZGX8T+VdPM4l/+7u6+p/v2qvd0C0G5p2N19m6TDXegLgA5q8gHdA2b2ZvUy/7K6XzKzTWY2aGbxG3IAHdVq2H8s6UpJayQNS/pR3S+6+2Z3X+vua1u8LQBt0FLY3f1Ddz/r7uckPSFpXXu7BaDdWgq7mY3dM/Z2STvrfhdAf0jH2c3sKUk3SJpjZvsk/VDSDWa2RpJLGpL03XZ05rrrrgvrx48fr61lY7KnTp1qqU/nRWP8Z86cCdsePhx/vhntry7lY8IzZsyorWXz2bPjls37zo5rtk5AE9n5C9FYeXb+wcGDB8N6030Ior5He7dL0qFDh2pr0XkP6T3h7nePc/FPsnYA+gunywKFIOxAIQg7UAjCDhSCsAOF6OoU1wULFmjjxo219WjqnhQvsZtNxcymDWZDKdFQTTZFNVvyOOtbNsX12LFjtbVs6CwbGsumemZTZKPjmvUtE01hleLHS7Y8d9Mp09mQZ3SfzZ49O2wbDUFHQ348swOFIOxAIQg7UAjCDhSCsAOFIOxAIQg7UIiujrMfPXpUL7zwQm19/fr1Yfto7DIb782mHGZj3VF99+7dYdvs/IGZM2eG9exvW7JkSW0tG6PPpudmWw9n9egcg6bnPmRTf7PzHyJHjx4N6023fI4MDQ2F9WicPbq/eWYHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQXR1nP3nypHbs2FFbz+bxNpljnM0vzq47GrNdvnx52DYb48+Wkl61alVYf+ihh2prr732Wtj20UcfDeurV68O69ky2dEy16dPnw7bZuPw2TkCUfspU6aEbRctWhTWs7n02fkN0ToC2d8VndcRnffAMztQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4WwJvNuv/KNmYU3tmHDhrD9I488El132DYbV83G4adPn95STcrH2bN525m9e/fW1vbt2xe2zc4RWLt2bVjPxtmjvy27T7K58keOHAnrkexxv3Xr1rCerTt/5ZVXhvXLL7+8tpbNpb/++uvDuruPG4b0UWZmS8zs12b2tpntMrPvV5cPmNlWM3u3+npZdl0AemciTykjkv7O3a+V9GeSvmdm10l6WNKr7r5S0qvVzwD6VBp2dx929zeq749JelvSYkm3StpS/doWSbd1qI8A2uArnRtvZkslfVPSbyTNd/dhafQ/BDObV9Nmk6RNDfsJoKEJh93Mpkl6WtKD7v5J9oHYee6+WdLm6jq692kggM+Z0MfAZnahRoP+M3d/prr4QzNbWNUXSjrQmS4CaId06M1Gn8K3SDrs7g+OufxfJH3k7o+b2cOSBty9fq6lmj+zR0M1y5YtC9vedNNNYX3evHHfhfzBunXramsjIyONrjtb8njWrFlhPZoumS1DnU2nzIbWomWNpXjqcPbYy4Y0s75HS2yvWLEibPvee++F9aaiobtsiexou2epfuhtIi/jN0i6R9JbZrajuuwHkh6X9Asz2yjpd5K+M4HrAtAjadjd/X8k1b1Bv7G93QHQKZwuCxSCsAOFIOxAIQg7UAjCDhSiq0tJZ7JppidOnKit7dq1K2yb1TtpYGAgrEfbGkvSNddcE9ajsexoKqWUj2VnSypny0HPmTOntnbw4MGwbXT+gJQvk33//ffX1pYuXRq2zcbZs8dqNq05OkcgO3+gVTyzA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQiL5aShpAcy0vJQ3gjwNhBwpB2IFCEHagEIQdKARhBwpB2IFCEHagEIQdKARhBwpB2IFCEHagEIQdKARhBwpB2IFCpGE3syVm9msze9vMdpnZ96vLHzOz981sR/Xvls53F0Cr0sUrzGyhpIXu/oaZTZe0XdJtkv5K0nF3/9cJ3xiLVwAdV7d4xUT2Zx+WNFx9f8zM3pa0uL3dA9BpX+k9u5ktlfRNSb+pLnrAzN40syfN7LKaNpvMbNDMBpt1FUATE16DzsymSXpN0j+5+zNmNl/SIUku6R81+lL/b5Lr4GU80GF1L+MnFHYzu1DS85Jedvd/G6e+VNLz7r46uR7CDnRYywtOmplJ+omkt8cGvfrg7rzbJe1s2kkAnTORT+O/Jem/Jb0l6Vx18Q8k3S1pjUZfxg9J+m71YV50XTyzAx3W6GV8uxB2oPNYNx4oHGEHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQhB0oBGEHCpEuONlmhyT935if51SX9aN+7Vu/9kuib61qZ9+uqCt0dT77l27cbNDd1/asA4F+7Vu/9kuib63qVt94GQ8UgrADheh12Df3+PYj/dq3fu2XRN9a1ZW+9fQ9O4Du6fUzO4AuIexAIXoSdjO72czeMbM9ZvZwL/pQx8yGzOytahvqnu5PV+2hd8DMdo65bMDMtprZu9XXcffY61Hf+mIb72Cb8Z4eu15vf9719+xmNlnSbyV9W9I+Sa9Lutvdd3e1IzXMbEjSWnfv+QkYZvbnko5L+o/zW2uZ2T9LOuzuj1f/UV7m7n/fJ317TF9xG+8O9a1um/G/Vg+PXTu3P29FL57Z10na4+573f20pJ9LurUH/eh77r5N0uEvXHyrpC3V91s0+mDpupq+9QV3H3b3N6rvj0k6v814T49d0K+u6EXYF0v6/Zif96m/9nt3Sa+Y2XYz29Trzoxj/vlttqqv83rcny9Kt/Hupi9sM943x66V7c+b6kXYx9uapp/G/za4+59K+ktJ36termJifizpSo3uATgs6Ue97Ey1zfjTkh5090962ZexxulXV45bL8K+T9KSMT9/Q9L+HvRjXO6+v/p6QNKzGn3b0U8+PL+DbvX1QI/78wfu/qG7n3X3c5KeUA+PXbXN+NOSfubuz1QX9/zYjdevbh23XoT9dUkrzWyZmV0k6S5Jz/WgH19iZlOrD05kZlMl3aT+24r6OUn3Vt/fK+mXPezL5/TLNt5124yrx8eu59ufu3vX/0m6RaOfyL8n6R960Yeafi2X9L/Vv1297pukpzT6su6MRl8RbZQ0W9Krkt6tvg70Ud/+U6Nbe7+p0WAt7FHfvqXRt4ZvStpR/bul18cu6FdXjhunywKF4Aw6oBCEHSgEYQcKQdiBQhB2oBCEHSgEYQcK8f9CTYbGv/facQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO -- hay que implementar esto\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "\n",
    "class RandomTriplets(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset en el que los elementos son triples obtenidos de forma aleatoria\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_data: Dataset, custom_len: int, transform = None):\n",
    "        self.base_data = base_data\n",
    "        self.custom_len = custom_len\n",
    "        self.transform = transform\n",
    "        self.random_sampler = RandomSampler(self.base_data, replacement=True, num_samples=1, generator=None)\n",
    "        \n",
    "        # Por motivos de eficiencia, pre-computamos una lista de listas, de forma\n",
    "        # que tengamos disponibles las listas con las posiciones de cada clase por\n",
    "        # separado.\n",
    "        self.posiciones_clases = self.__precompute_list_of_classes()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Devolvemos el tamaño del dataset\n",
    "        Como estamos generando triples aleatorios, devolvemos el tamaño definido\n",
    "        por parametro\n",
    "        \"\"\"\n",
    "        return self.custom_len\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Funcion que es llamada cuando se hace dataset[idx]\n",
    "        En vez de devolver una imagen (que es lo comun en esta clase dataset), \n",
    "        devolvemos un triple (anchor, positive, negative) aleatorio\n",
    "        \"\"\"\n",
    "\n",
    "        # Hacemos esto por temas de eficiencia\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Tomamos una imagen aleatoria que sera el ancla\n",
    "        anchor, anchor_class = self.base_data[next(iter(self.random_sampler))]\n",
    "\n",
    "        # Tomamos una imagen de la misma clase, que sera la positiva, de forma aleatoria\n",
    "        random_index = np.random.choice(self.posiciones_clases[anchor_class])\n",
    "        positive, positive_class = self.base_data[random_index]\n",
    "\n",
    "        # Tomamos una imagen de otra clase, que sera la negativa\n",
    "        # Empiezo tomando una clase que no sea la del anchor\n",
    "        posible_classes = list(range(10))\n",
    "        posible_classes.remove(anchor_class)\n",
    "        negative_class = np.random.choice(posible_classes)\n",
    "\n",
    "        # Ahora tomamos un indice aleatorio de esta clase negativa\n",
    "        random_index = np.random.choice(self.posiciones_clases[negative_class])\n",
    "        negative, negative_class = self.base_data[random_index]\n",
    "        \n",
    "        # Generamos ahora el triple\n",
    "        triplet = [anchor, positive, negative]\n",
    "\n",
    "        # Aplicamos la transformacion dada al dataset al ejemplo que devolvemos\n",
    "        if self.transform:\n",
    "            triplet = [self.transform(np.array(img)) for img in triplet]\n",
    "\n",
    "        return np.array(triplet)\n",
    "\n",
    "    def __precompute_list_of_classes(self) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Calcula la lista con las listas de posiciones de cada clase por separado\n",
    "        \"\"\"\n",
    "        # Inicializamos la lista de listas\n",
    "        posiciones_clases = [[] for _ in range(10)]\n",
    "\n",
    "        # Recorremos el dataset y colocamos los indices donde corresponde\n",
    "        for idx, element in enumerate(self.base_data):\n",
    "            _, img_class = element\n",
    "            posiciones_clases[img_class].append(idx)\n",
    "\n",
    "        return posiciones_clases\n",
    "\n",
    "    \n",
    "class CustomReshape(object):\n",
    "    \"\"\"Pasamos la imagen de (28, 1, 28) a (1, 28, 28)\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = image.reshape(28, 28)\n",
    "        return image\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Hacemos reshape de las imagenes para\n",
    "    # que sean tensores (28, 28)\n",
    "    CustomReshape(),\n",
    "])\n",
    "\n",
    "random_triplets = RandomTriplets(\n",
    "    base_data = train_dataset,\n",
    "    custom_len = RANDOM_TRIPLETS_DATA_SIZE,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "# TODO -- esto habria que borrarlo, esta aqui para hacer pruebas\n",
    "#Visualizamos un triple\n",
    "custom_triplet = random_triplets[2]\n",
    "for i in custom_triplet :\n",
    "    show_img(i, color_format_range = (-1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO -- esto esta aqui por si la otra forma de cargar los datos no va bien\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, df, train=True, transform=None):\n",
    "        self.is_train = train\n",
    "        self.transform = transform\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "        \n",
    "        if self.is_train:            \n",
    "            self.images = df.iloc[:, 1:].values.astype(np.uint8)\n",
    "            self.labels = df.iloc[:, 0].values\n",
    "            self.index = df.index.values\n",
    "        else:\n",
    "            self.images = df.values.astype(np.uint8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        anchor_img = self.images[item].reshape(28, 28, 1)\n",
    "        \n",
    "        if self.is_train:\n",
    "            anchor_label = self.labels[item]\n",
    "\n",
    "            positive_list = self.index[self.index!=item][self.labels[self.index!=item]==anchor_label]\n",
    "\n",
    "            positive_item = random.choice(positive_list)\n",
    "            positive_img = self.images[positive_item].reshape(28, 28, 1)\n",
    "            negative_list = self.index[self.index!=item][self.labels[self.index!=item]!=anchor_label]\n",
    "            negative_item = random.choice(negative_list)\n",
    "            negative_img = self.images[negative_item].reshape(28, 28, 1)\n",
    "            \n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(self.to_pil(anchor_img))\n",
    "                positive_img = self.transform(self.to_pil(positive_img))\n",
    "                negative_img = self.transform(self.to_pil(negative_img))\n",
    "            \n",
    "            return anchor_img, positive_img, negative_img, anchor_label\n",
    "        \n",
    "        else:\n",
    "            if self.transform:\n",
    "                anchor_img = self.transform(self.to_pil(anchor_img))\n",
    "            return anchor_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a17b1e1"
   },
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        # TODO -- podemos mirar de usar numpy porque deberia ir el triple de rapido\n",
    "        # TODO -- de hecho podemos mirar para hacerlo directamente con torch\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Comprobaciones de seguridad\n",
    "        if anchor.shape[0] != 1 or positive.shape[0] != 1 or negative.shape[0] != 1:\n",
    "            \n",
    "            # Construimos el mensaje de error para saber que ha fallado\n",
    "            err_msg = \"Los tensores dados deben tener un unico elemento \\n\"\n",
    "            err_msg += f\"anchor.shape = {anchor.shape}\\n\"\n",
    "            err_msg += f\"positive.shape = {positive.shape}\\n\"\n",
    "            err_msg += f\"negative.shape = {negative.shape}\\n\"\n",
    "            \n",
    "            # Levantamos la excepcion con el mensaje\n",
    "            raise ValueError(err_msg)\n",
    "        \n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "\n",
    "        # TODO -- mirar por que se hace RELU aqui\n",
    "        loss = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class TripletLossCustom(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLossCustom, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.base_loss = TripletLoss(self.margin)\n",
    "    \n",
    "    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        losses = np.array([self.base_loss(current[0], current[1], current[2]) for current in batch])\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    net: nn.Module,\n",
    "    path: str,\n",
    "    parameters: dict,\n",
    "    train_loader: DataLoader,\n",
    "    validation_loader: DataLoader = None,\n",
    "    name: str = \"Model\",\n",
    "    logger: TrainLogger = None,\n",
    "    snapshot_iterations: int = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Trains and saves a neural net\n",
    "\n",
    "    Parameters:\n",
    "    ===========\n",
    "    net: Module representing a neural net to train\n",
    "    path: dir where models are going to be saved\n",
    "    parameters: dict having the following data:\n",
    "                - \"lr\": learning rate\n",
    "                - \"momentum\": momentum of the optimizer\n",
    "                - \"criterion\": loss function\n",
    "                - \"epochs\": epochs to train\n",
    "    train_loader: pytorch DataLoader wrapping training set\n",
    "    validation_loader: pytorch DataLoader wrapping validation set\n",
    "    name: name of the model, in order to save it\n",
    "    train_logger: to log data about trainning process\n",
    "                  Default logger is silent logger\n",
    "    snapshot_iterations: at how many iterations we want to take an snapshot of the model\n",
    "                         If its None, no snapshots are taken\n",
    "    \"\"\"\n",
    "\n",
    "    # Loss and optimizer\n",
    "    lr = parameters[\"lr\"]\n",
    "    momentum = parameters[\"momentum\"]\n",
    "    criterion = parameters[\"criterion\"]\n",
    "    \n",
    "    # TODO -- usar ADAM en vez de SGD\n",
    "    optimizer = optim.SGD(net.parameters(), lr = lr, momentum = momentum)\n",
    "\n",
    "    # Select proper device and move the net to that device\n",
    "    device = core.get_device()\n",
    "    net.to(device)\n",
    "\n",
    "    # Check if no logger is given\n",
    "    if logger is None:\n",
    "        print(\"==> No logger given, using Silent Logger\")\n",
    "        logger = SilentLogger()\n",
    "\n",
    "    # Printing where we're training\n",
    "    print(f\"==> Training on device {device}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Training the network\n",
    "    epochs = parameters[\"epochs\"]\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            \n",
    "            print(f\"TODO -- data.shape == {data.shape}\")\n",
    "            print(f\"TODO -- data[0].shape == {data[0].shape}\")\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = [net(item) for item in data]\n",
    "            loss = criterion(outputs)\n",
    "\n",
    "            # Backward + Optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics -- important, we have to use the iteration given by current epoch and current\n",
    "            # iteration counter in inner loop. Otherwise logs are going to be non-uniform over iterations\n",
    "            curr_it = epoch * len(train_loader.dataset) + i * train_loader.batch_size\n",
    "            if logger.should_log(curr_it):\n",
    "                logger.log_process(train_loader, validation_loader, epoch, i)\n",
    "\n",
    "            # Snapshots -- same as Statistics, we reuse current iteration calc\n",
    "            # TODO -- create a SnapshotTaker class as we have for logs -- snapshot_taker.should_log(i)\n",
    "            if snapshot_iterations is not None and curr_it % snapshot_iterations == 0:\n",
    "                # We take the snapshot\n",
    "                snapshot_name = \"snapshot_\" + name + \"==\" + get_datetime_str()\n",
    "                snapshot_folder = os.path.join(path, \"snapshots\")\n",
    "                filesystem.save_model(net, folder_path = snapshot_folder, file_name = snapshot_name)\n",
    "\n",
    "    print(\"Finished training\")\n",
    "\n",
    "    # Save the model -- use name + date stamp to save the model\n",
    "    date = get_datetime_str()\n",
    "    name = name + \"==\" + date\n",
    "    filesystem.save_model(net = net, folder_path = path, name = name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (pretrained): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ResNet18().cuda()\n",
    "\n",
    "# TODO -- fijar bien los parametros\n",
    "parameters = dict()\n",
    "parameters[\"epochs\"] = TRAINING_EPOCHS\n",
    "parameters[\"lr\"] = 0.001\n",
    "parameters[\"momentum\"] = 0.9\n",
    "parameters[\"criterion\"] = TripletLossCustom(MARGIN)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> No logger given, using Silent Logger\n",
      "==> Training on device cuda:0\n",
      "\n",
      "TODO -- data.shape == (3,)\n",
      "TODO -- data[0].shape == torch.Size([28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-056deb44c6f0>:64: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array(triplet)\n",
      "<ipython-input-10-056deb44c6f0>:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(triplet)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 2-dimensional input of size [28, 28] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-396676e5546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tmp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_triplets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5d2b60ce076f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, path, parameters, train_loader, validation_loader, name, logger, snapshot_iterations)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5d2b60ce076f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2469c30b840a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Usamos directamente la red pre-entrenada para hacer el forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 2-dimensional input of size [28, 28] instead"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    net = net,\n",
    "    path = os.path.join(BASE_PATH, \"tmp\"),\n",
    "    parameters = parameters,\n",
    "    train_loader = random_triplets,\n",
    "    \n",
    "    # TODO -- no tenemos conjunto de validacion\n",
    "    validation_loader = None,\n",
    "    name = \"SiameseNetwork\",\n",
    "    logger = None,\n",
    "    snapshot_iterations = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc92ce37"
   },
   "source": [
    "# Evaluación del modelo\n",
    "\n",
    "- Mostramos algunas métricas fundamentales sobre el conjunto de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2242eedc"
   },
   "outputs": [],
   "source": [
    "# TODO -- hay que implementar algunas metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c946904"
   },
   "source": [
    "# Adaptación del modelo para usarlo como clasificador\n",
    "\n",
    "- Nuestro modelo genera un *embedding*\n",
    "- Adaptamos el modelo para que, a partir de dicho embedding, podamos usarlo como un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d33aa9d"
   },
   "outputs": [],
   "source": [
    "# TODO -- adaptar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f644bbed"
   },
   "source": [
    "## Evaluación del clasificador obtenido\n",
    "\n",
    "- Ahora que hemos adaptado el modelo para usarlo como clasificador, podemos consultar ciertas métricas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "030af6e5"
   },
   "outputs": [],
   "source": [
    "# TODO -- implementar las métricas de clasificación"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
