{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5a81f04a-501e-4edc-8376-2b212f058640",
      "metadata": {
        "id": "5a81f04a-501e-4edc-8376-2b212f058640",
        "tags": []
      },
      "source": [
        "# Parámetros globales del *Notebook*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dafe6cb7-f4e8-4aa1-8368-19c0bf273dac",
      "metadata": {
        "id": "dafe6cb7-f4e8-4aa1-8368-19c0bf273dac"
      },
      "outputs": [],
      "source": [
        "# Para definir los path\n",
        "import os\n",
        "\n",
        "# Define si estamos ejecutando el Notebook en nuestro \n",
        "# ordenador (\"local\") o en Google Colab (\"remote\")\n",
        "RUNNING_ENV = \"remote\"\n",
        "\n",
        "# Path que vamos a usar como base para el resto de paths\n",
        "BASE_PATH = \"./\" if RUNNING_ENV == \"local\" else \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "# Directorio en el que guardamos los scripts de python que usamos \n",
        "# como libreria propia\n",
        "LIB_PATH = os.path.join(BASE_PATH, \"lib\")\n",
        "\n",
        "# Directorio en el que guardamos los datos de entrenamiento y test\n",
        "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
        "\n",
        "# Numero de procesos que queremos usar\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Batch size que queremos usar para los dataloaders que usamos\n",
        "DATALOADER_BACH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81fd5e8-320b-4e00-be57-4bdf5799dad1",
      "metadata": {
        "id": "a81fd5e8-320b-4e00-be57-4bdf5799dad1"
      },
      "source": [
        "# Autorización si estamos usando Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6fcac799-d53f-4e6d-aaf4-4e7df3ae7422",
      "metadata": {
        "id": "6fcac799-d53f-4e6d-aaf4-4e7df3ae7422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4f7a97-b1e9-4a0d-e07e-4ea991987663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if RUNNING_ENV == \"remote\":\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638c766e-6f30-46d7-b6d3-97a6b7e30995",
      "metadata": {
        "id": "638c766e-6f30-46d7-b6d3-97a6b7e30995"
      },
      "source": [
        "# Importando los módulos que vamos a usar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3aeb81a8-78a0-4e63-aa9d-3c82d24100b5",
      "metadata": {
        "id": "3aeb81a8-78a0-4e63-aa9d-3c82d24100b5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Cargamos en el Notebook todos los ficheros .py que definen nuestra propia libreria\n",
        "# Usamos esta libreria para escribir el codigo base necesario para llevar a cabo ciertas\n",
        "# tareas del notebook (como el bucle de entrenamiento) que no tienen interes mostrar\n",
        "# en este notebook\n",
        "!cp -r \"$LIB_PATH\"/* .\n",
        "\n",
        "# Ahora que hemos cargado estos ficheros en el Notebook, importamos lo necesario\n",
        "# de nuestra propia libreria\n",
        "import core\n",
        "import board\n",
        "import filesystem\n",
        "from train_loggers import ClassificationLogger, SilentLogger, TripletLogger\n",
        "from models.resnet import *\n",
        "from visualizations import *\n",
        "from custom_loss import triplet_loss_batch_hard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones comunes que vamos a usar en el notebook"
      ],
      "metadata": {
        "id": "BG5J8TTV2CvZ"
      },
      "id": "BG5J8TTV2CvZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO -- de momento no tenemos nada asi que esto ahora mismo lo podriamos borrar"
      ],
      "metadata": {
        "id": "yTstfi4k2CBu"
      },
      "id": "yTstfi4k2CBu",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b4cbeab3-125d-44e4-8734-928f8f0c664c",
      "metadata": {
        "id": "b4cbeab3-125d-44e4-8734-928f8f0c664c"
      },
      "source": [
        "# Carga del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "faa50ba8-0f5f-420e-bcbc-cfffc165ee44",
      "metadata": {
        "id": "faa50ba8-0f5f-420e-bcbc-cfffc165ee44"
      },
      "outputs": [],
      "source": [
        "# Transformaciones que queremos aplicar al cargar los datos\n",
        "# Ahora solo pasamos las imagenes a tensores, pero podriamos hacer aqui normalizaciones\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # TODO -- aqui podemos añadir la normaliazcion de datos\n",
        "])\n",
        "\n",
        "# Cargamos el dataset usando torchvision, que ya tiene el conjunto\n",
        "# preparado para descargar\n",
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = DATA_PATH,\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = DATA_PATH,\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")\n",
        "\n",
        "# Data loaders para acceder a los datos\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = DATALOADER_BACH_SIZE,\n",
        "    shuffle = True,\n",
        "    num_workers = NUM_WORKERS,\n",
        "    pin_memory = True,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  train_dataset,\n",
        "  batch_size = DATALOADER_BACH_SIZE,\n",
        "  shuffle = True,\n",
        "  num_workers = NUM_WORKERS,\n",
        "  pin_memory = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definiendo las clases con las que vamos a trabajar"
      ],
      "metadata": {
        "id": "Xk77zxIm2SsI"
      },
      "id": "Xk77zxIm2SsI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Clases con las que vamos a trabajar\n",
        "# Esta lista especifica la relacion numero -> nombre de la forma\n",
        "# classes[numero] = nombre\n",
        "classes = (\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        ")"
      ],
      "metadata": {
        "id": "fCDY7GM02SBk"
      },
      "id": "fCDY7GM02SBk",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "84d5b0ca-5a5a-4a4b-b0f4-dd6cf021f73d",
      "metadata": {
        "id": "84d5b0ca-5a5a-4a4b-b0f4-dd6cf021f73d",
        "tags": []
      },
      "source": [
        "# Análisis Exploratorio de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3a17a3-c502-41ef-8197-b0c6989e9402",
      "metadata": {
        "id": "7b3a17a3-c502-41ef-8197-b0c6989e9402"
      },
      "source": [
        "Mostramos algunas imágenes con sus clases para asegurar que hemos cargado correctamente las imágenes del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "816b14ed-0a49-44f5-ac5b-16dce9e58091",
      "metadata": {
        "id": "816b14ed-0a49-44f5-ac5b-16dce9e58091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffddc4f3-1a43-45a4-f834-4b69a4307e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase obtenida es: Dress\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase obtenida es: Sandal\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase obtenida es: Ankle boot\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase obtenida es: Pullover\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase obtenida es: Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "imgs_to_show = 5\n",
        "\n",
        "for _ in range(imgs_to_show):\n",
        "\n",
        "    # Cargamos un batch de imagenes\n",
        "    images, images_classes = next(iter(train_loader))\n",
        "\n",
        "    # Nos quedamos con la primera imagen del batch\n",
        "    img, img_class = images[0], images_classes[0]\n",
        "\n",
        "    # Mostramos alguna informacion de la imagen\n",
        "    print(f\"La clase obtenida es: {classes[img_class]}\")\n",
        "\n",
        "    # Re-escalamos y mostramos la imagen\n",
        "    img = img.reshape((28, 28))\n",
        "    show_img(img, color_format_range = (-1.0, 1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11747bce-2a7e-4c9c-bcc0-d22989a6faf0",
      "metadata": {
        "id": "11747bce-2a7e-4c9c-bcc0-d22989a6faf0"
      },
      "source": [
        "Mostramos ahora unas cuantas imágenes de forma simultánea:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a73b156-19f0-470e-ad06-e140bc65a61c",
      "metadata": {
        "id": "0a73b156-19f0-470e-ad06-e140bc65a61c"
      },
      "source": [
        "Mostramos ahora los tamaños del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1f3dcc8-0482-446d-a686-e4e7ca9b6afd",
      "metadata": {
        "id": "f1f3dcc8-0482-446d-a686-e4e7ca9b6afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346b6a17-0eda-4ab1-84c4-421764d99d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 60000 imágenes de entrenamiento\n",
            "Tenemos 10000 imágenes de test\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tenemos {len(train_dataset)} imágenes de entrenamiento\")\n",
        "print(f\"Tenemos {len(test_dataset)} imágenes de test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905faa72-9a5a-48d9-ae70-405b69ef1c6f",
      "metadata": {
        "id": "905faa72-9a5a-48d9-ae70-405b69ef1c6f"
      },
      "source": [
        "# Definiendo el modelo base\n",
        "\n",
        "- A continuación, definimos el modelo que vamos a usasr como base para nuestra red siamesa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "81a157dc-fe12-46d4-9369-84514c80486c",
      "metadata": {
        "id": "81a157dc-fe12-46d4-9369-84514c80486c"
      },
      "outputs": [],
      "source": [
        "# TODO -- lo suyo seria usar un modelo pre-entrenado como ResNet12 como modelo base\n",
        "\n",
        "class LuNet(nn.Module):\n",
        "    \"\"\"\n",
        "    LuNet model adapted to 28x28x1 input images\n",
        "    \n",
        "    Based on the model presented in the paper \"In defense of the triplet loss \n",
        "    for person re-identification\"\n",
        "    \n",
        "    In order to make some experiments with this model\n",
        "    \n",
        "    Original architecture is quite similar to a common ResNet using bottleneck \n",
        "    building blocks with batch normalization. The real work happens in the \n",
        "    loss function and also the way triplets are chosen. So we are going to \n",
        "    stack some building blocks without max-pooling (28x28x1 is small enough)\n",
        "    and apply that loss function and triplet selection policy\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):          \n",
        "        # Init parent class\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNet Blocks\n",
        "        self.block1 = BottleNeckBlock(\n",
        "            input_channels = 1,\n",
        "            output_channels = 8,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            disable_identity = True,\n",
        "        )\n",
        "        \n",
        "        self.block2 = BottleNeckBlock(\n",
        "            input_channels = 8,\n",
        "            output_channels = 8,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            disable_identity = False,\n",
        "        )\n",
        "        \n",
        "        self.block3 = BottleNeckBlock(\n",
        "            input_channels = 8,\n",
        "            output_channels = 16,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            disable_identity = True,\n",
        "        )\n",
        "        \n",
        "        self.block4 = BottleNeckBlock(\n",
        "            input_channels = 16,\n",
        "            output_channels = 16,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            disable_identity = False,\n",
        "        )\n",
        "        \n",
        "        # Fully connected layers\n",
        "        # We end up with an embedding space of dimension 64\n",
        "        self.fc1 = nn.Linear(12544, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # ResNet blocks\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        \n",
        "        # Now fully-connected layers\n",
        "        x = torch.flatten(x, start_dim = 1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        # TODO -- enable this again\n",
        "        #x = self.bn1(x)\n",
        "        x = F.relu(x)        \n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de triples\n",
        "\n",
        "- Para entrenar la red siamesa, necesitamos dar triples con los que computar el *triplet loss*\n",
        "- Por ello, es necesaria una fase previa de *triplets mining*\n",
        "- En todos los casos, crearemos *Datasets* de *Pytorch* para representar la creación de los triples\n",
        "- Hacemos esto basándonos el la [documentación oficial de Pytorch](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
      ],
      "metadata": {
        "id": "4sVnhIQg31k5"
      },
      "id": "4sVnhIQg31k5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de triples aleatorios\n",
        "\n",
        "- Es la forma más sencilla y directa para generar triples\n",
        "- Usaremos esta generación como baseline para más tarde realizar comparaciones"
      ],
      "metadata": {
        "id": "WvUGOBKU6WKG"
      },
      "id": "WvUGOBKU6WKG"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO -- hay que implementar esto\n",
        "from torch.utils.data import RandomSampler\n",
        "\n",
        "\n",
        "class RandomTriplets(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset en el que los elementos son triples obtenidos de forma aleatoria\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_data: Dataset, custom_len: int, transform = None):\n",
        "        self.base_data = base_data\n",
        "        self.custom_len = custom_len\n",
        "        self.transform = transform\n",
        "        self.random_sampler = RandomSampler(self.base_data, replacement=True, num_samples=1, generator=None)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Devolvemos el tamaño del dataset\n",
        "        Como estamos generando triples aleatorios, devolvemos el tamaño definido\n",
        "        por parametro\n",
        "        \"\"\"\n",
        "        return self.custom_len\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Funcion que es llamada cuando se hace dataset[idx]\n",
        "        En vez de devolver una imagen (que es lo comun en esta clase dataset), \n",
        "        devolvemos un triple (anchor, positive, negative) aleatorio\n",
        "        \"\"\"\n",
        "\n",
        "        # Hacemos esto por temas de eficiencia\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Tomamos una imagen aleatoria que sera el ancla\n",
        "        anchor, anchor_class = self.base_data[next(iter(self.random_sampler))]\n",
        "\n",
        "        # Tomamos una imagen de la misma clase, que sera la positiva\n",
        "        # TODO -- hay que hacer que de algun modo sea de la misma clase\n",
        "        positive, positive_class = self.base_data[next(iter(self.random_sampler))]\n",
        "\n",
        "        # Tomamos una imagen de otra clase, que sera la negativa\n",
        "        # TODO -- hay que hacer que de algun modo sea de una clase distinta\n",
        "        negative, negative_class = self.base_data[next(iter(self.random_sampler))]\n",
        "\n",
        "        # TODO -- borrar este logging porque va a hacer que vaya mas lento\n",
        "        print(f\"La clase anchor es {anchor_class}\")\n",
        "        print(f\"La clase positiva es {positive_class}\")\n",
        "        print(f\"La clase negativa es {negative_class}\")\n",
        "        \n",
        "        # Generamos ahora el triple\n",
        "        triplet = [anchor, positive, negative]\n",
        "\n",
        "        # Aplicamos la transformacion dada al dataset al ejemplo que devolvemos\n",
        "        if self.transform:\n",
        "            triplet = [self.transform(img) for img in triplet]\n",
        "\n",
        "        return triplet\n",
        "\n",
        "\n",
        "random_triplets = RandomTriplets(\n",
        "    base_data = train_dataset,\n",
        "    custom_len = len(train_dataset) * 3,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "custom_triplet = random_triplets[2]\n",
        "print(\"Funciona\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "tjNWBh-B3--F",
        "outputId": "364be0d2-f6b5-4385-af70-88eb08601ec1"
      },
      "id": "tjNWBh-B3--F",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La clase anchor es 9\n",
            "La clase positiva es 7\n",
            "La clase negativa es 7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c6a3628d03bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mcustom_triplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_triplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Funciona\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c6a3628d03bd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Aplicamos la transformacion dada al dataset al ejemplo que devolvemos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtriplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriplet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriplet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c6a3628d03bd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Aplicamos la transformacion dada al dataset al ejemplo que devolvemos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtriplet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriplet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriplet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be PIL Image or ndarray. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f272b8-b501-49c2-8aa7-77a7abe85614",
      "metadata": {
        "id": "64f272b8-b501-49c2-8aa7-77a7abe85614"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29de921-e5d9-4319-bf01-1f65e651d734",
      "metadata": {
        "id": "c29de921-e5d9-4319-bf01-1f65e651d734"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "parameters = dict()\n",
        "parameters[\"lr\"] = 0.001\n",
        "parameters[\"momentum\"] = 0.9\n",
        "parameters[\"criterion\"] = triplet_loss_batch_hard\n",
        "parameters[\"epochs\"] = 10\n",
        "\n",
        "# We save the model in different paths wether we're running\n",
        "# local or in cloud\n",
        "# TODO -- esto ponerlo en constantes y con buenos nombres\n",
        "save_model_path = None\n",
        "if RUNNING_ENV == \"local\": save_model_path = \"./saved_models\"\n",
        "if RUNNING_ENV == \"remote\": save_model_path = \"drive/MyDrive/ml/Modelos/MNIST-ReID/saved_models\"\n",
        "\n",
        "# Network we are going to train\n",
        "net = LuNet()\n",
        "\n",
        "# Specifying the trainning logger\n",
        "logger = TripletLogger(\n",
        "    iterations = 200 * batch_size, # TODO -- document why multiplying batch_size \n",
        "    loss_func = triplet_loss_batch_hard, \n",
        "    net = net,\n",
        "    training_perc = 0.2, \n",
        "    validation_perc = 1.0\n",
        ")\n",
        "\n",
        "# If running in cloud, show tensorboard inline\n",
        "if RUNNING_ENV == \"remote\":\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir runs\n",
        "\n",
        "# Train process\n",
        "core.batch_hard_train(\n",
        "    net, \n",
        "    save_model_path, \n",
        "    parameters, \n",
        "    train_loader = train_loader, \n",
        "    validation_loader = test_loader, # TODO -- we are using test dataset as validation dataset \n",
        "    name = \"LuNet\", \n",
        "    logger = logger,\n",
        "    snapshot_iterations = 10_000 \n",
        ")\n",
        "\n",
        "# Close the logger when we are done with the training\n",
        "logger.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aadebb34-b01d-4a6e-831f-7de00f182789",
      "metadata": {
        "id": "aadebb34-b01d-4a6e-831f-7de00f182789"
      },
      "source": [
        "# Evaluación del modelo\n",
        "\n",
        "- Mostramos algunas métricas fundamentales sobre el conjunto de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1957da-c16c-4f92-a9cd-51e8ba5831f6",
      "metadata": {
        "id": "fd1957da-c16c-4f92-a9cd-51e8ba5831f6"
      },
      "outputs": [],
      "source": [
        "# TODO -- hay que implementar algunas metricas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptación del modelo para usarlo como clasificador\n",
        "\n",
        "- Nuestro modelo genera un *embedding*\n",
        "- Adaptamos el modelo para que, a partir de dicho embedding, podamos usarlo como un clasificador"
      ],
      "metadata": {
        "id": "X_EJAcbN4Sbm"
      },
      "id": "X_EJAcbN4Sbm"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO -- adaptar el modelo"
      ],
      "metadata": {
        "id": "2_QCYk4d4m_P"
      },
      "id": "2_QCYk4d4m_P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del clasificador obtenido\n",
        "\n",
        "- Ahora que hemos adaptado el modelo para usarlo como clasificador, podemos consultar ciertas métricas de clasificación"
      ],
      "metadata": {
        "id": "-WVrgOGu4ovB"
      },
      "id": "-WVrgOGu4ovB"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO -- implementar las métricas de clasificación"
      ],
      "metadata": {
        "id": "pyhpnGXG4vdr"
      },
      "id": "pyhpnGXG4vdr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}